{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Search.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhU7By0H2okj"
      },
      "source": [
        "# Search Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjnFMIKhMMCF"
      },
      "source": [
        "Take the search query as input and find the most similar question in the database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7NPyD3R2uJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d68207-c742-4302-f4e7-0b829a93b482"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "1JcAJbLZ2okp"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from nltk import RegexpTokenizer\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "import spacy\n",
        "EN = spacy.load('en_core_web_sm')\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "import logging\n",
        "logging.getLogger('tensorflow').disabled = True "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9T8PG0b2okw"
      },
      "source": [
        "## Import Database and Word Embedding Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "brMSwD9n2okx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "6ed873b4-f7b7-4787-d09e-63649446d860"
      },
      "source": [
        "data = pd.read_csv('/content/gdrive/My Drive/Stackoverflow_VS_extension/Preprocessed_data.csv')\n",
        "data"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_title</th>\n",
              "      <th>post_corpus</th>\n",
              "      <th>question_content</th>\n",
              "      <th>question_url</th>\n",
              "      <th>tags</th>\n",
              "      <th>overall_scores</th>\n",
              "      <th>answers_content</th>\n",
              "      <th>processed_title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Using 'in' to match an attribute of Python obj...</td>\n",
              "      <td>using match attribute python objects array nt ...</td>\n",
              "      <td>using match attribute python objects array nt ...</td>\n",
              "      <td>https://stackoverflow.com/questions/683</td>\n",
              "      <td>python|arrays|iteration</td>\n",
              "      <td>0.011301</td>\n",
              "      <td>Using a list comprehension would build a tempo...</td>\n",
              "      <td>using match attribute python objects array</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Python version of PHP's stripslashes</td>\n",
              "      <td>python version php stripslashes wrote piece co...</td>\n",
              "      <td>python version php stripslashes wrote piece co...</td>\n",
              "      <td>https://stackoverflow.com/questions/13454</td>\n",
              "      <td>python|string|escaping</td>\n",
              "      <td>0.001115</td>\n",
              "      <td>Python has a built-in escape() function analog...</td>\n",
              "      <td>python version php stripslashes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Unicode vs UTF-8 confusion in Python / Django?</td>\n",
              "      <td>unicode vs utf8 confusion python django stumbl...</td>\n",
              "      <td>unicode vs utf8 confusion python django stumbl...</td>\n",
              "      <td>https://stackoverflow.com/questions/22149</td>\n",
              "      <td>python|django|unicode</td>\n",
              "      <td>0.006997</td>\n",
              "      <td>From Wikipedia on UTF-8:</td>\n",
              "      <td>unicode vs utf8 confusion python django</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Using Django time/date widgets in custom form</td>\n",
              "      <td>using django time date widgets custom form use...</td>\n",
              "      <td>using django time date widgets custom form use...</td>\n",
              "      <td>https://stackoverflow.com/questions/38601</td>\n",
              "      <td>python|django</td>\n",
              "      <td>0.041431</td>\n",
              "      <td>Starting in Django 1.2 RC1, if you're using th...</td>\n",
              "      <td>using django time date widgets custom form</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Can parallel traversals be done in MATLAB just...</td>\n",
              "      <td>parallel traversals done matlab python using f...</td>\n",
              "      <td>parallel traversals done matlab python using f...</td>\n",
              "      <td>https://stackoverflow.com/questions/49307</td>\n",
              "      <td>python|arrays|matlab|for-loop</td>\n",
              "      <td>0.002837</td>\n",
              "      <td>should be for example:</td>\n",
              "      <td>parallel traversals done matlab python</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147054</th>\n",
              "      <td>How can I insert spaces between words given a ...</td>\n",
              "      <td>insert spaces words given list lists coded let...</td>\n",
              "      <td>insert spaces words given list lists coded let...</td>\n",
              "      <td>https://stackoverflow.com/questions/63758260</td>\n",
              "      <td>python|list|dictionary|spacing</td>\n",
              "      <td>-0.000607</td>\n",
              "      <td>Just append another whitespace in array:</td>\n",
              "      <td>insert spaces words given list lists coded let...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147055</th>\n",
              "      <td>Django creates another media folder inside med...</td>\n",
              "      <td>django creates another media folder inside med...</td>\n",
              "      <td>django creates another media folder inside med...</td>\n",
              "      <td>https://stackoverflow.com/questions/63758482</td>\n",
              "      <td>python|django|python-imaging-library</td>\n",
              "      <td>-0.000176</td>\n",
              "      <td>The  parameter [Django-doc] is relative to the...</td>\n",
              "      <td>django creates another media folder inside med...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147056</th>\n",
              "      <td>Options for deploying Flask app that continuou...</td>\n",
              "      <td>options deploying flask app continuously web s...</td>\n",
              "      <td>options deploying flask app continuously web s...</td>\n",
              "      <td>https://stackoverflow.com/questions/63758866</td>\n",
              "      <td>python|flask|heroku|web-scraping|web-applications</td>\n",
              "      <td>-0.000607</td>\n",
              "      <td>Have you tried using Cron? There is no cost no...</td>\n",
              "      <td>options deploying flask app continuously web s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147057</th>\n",
              "      <td>Delete \"nan\" in python list</td>\n",
              "      <td>delete nan python list new python simple quest...</td>\n",
              "      <td>delete nan python list new python simple quest...</td>\n",
              "      <td>https://stackoverflow.com/questions/63758902</td>\n",
              "      <td>python|list</td>\n",
              "      <td>-0.000750</td>\n",
              "      <td>You can ... get creative:my_list = ['experienc...</td>\n",
              "      <td>delete nan python list</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147058</th>\n",
              "      <td>Django : python manage.py runserver (multiple ...</td>\n",
              "      <td>django python managepy runserver multiple erro...</td>\n",
              "      <td>django python managepy runserver multiple erro...</td>\n",
              "      <td>https://stackoverflow.com/questions/63759220</td>\n",
              "      <td>python|python-3.x|django|ubuntu</td>\n",
              "      <td>-0.000750</td>\n",
              "      <td>The first thing you should do is to create a v...</td>\n",
              "      <td>django python managepy runserver multiple errors</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>147059 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           original_title  ...                                    processed_title\n",
              "0       Using 'in' to match an attribute of Python obj...  ...         using match attribute python objects array\n",
              "1                    Python version of PHP's stripslashes  ...                    python version php stripslashes\n",
              "2          Unicode vs UTF-8 confusion in Python / Django?  ...            unicode vs utf8 confusion python django\n",
              "3           Using Django time/date widgets in custom form  ...         using django time date widgets custom form\n",
              "4       Can parallel traversals be done in MATLAB just...  ...             parallel traversals done matlab python\n",
              "...                                                   ...  ...                                                ...\n",
              "147054  How can I insert spaces between words given a ...  ...  insert spaces words given list lists coded let...\n",
              "147055  Django creates another media folder inside med...  ...  django creates another media folder inside med...\n",
              "147056  Options for deploying Flask app that continuou...  ...  options deploying flask app continuously web s...\n",
              "147057                        Delete \"nan\" in python list  ...                             delete nan python list\n",
              "147058  Django : python manage.py runserver (multiple ...  ...   django python managepy runserver multiple errors\n",
              "\n",
              "[147059 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "WwC92GVf2ok2"
      },
      "source": [
        "import gensim\n",
        "w2v_model = gensim.models.word2vec.Word2Vec.load('/content/gdrive/My Drive/Stackoverflow_VS_extension/SO_word2vec_embeddings.bin')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlEeevzh2ok7"
      },
      "source": [
        "## Calculate Mean Embedding for a query\n",
        "In a query, take the mean value of the word embedding vector for each word and use this mean vector as the representation of the query. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "Q2-Tp-PB2ok8"
      },
      "source": [
        "def question_to_vec(question, embeddings, dim=300):\n",
        "    question_embedding = np.zeros(dim)\n",
        "    valid_words = 0\n",
        "    for word in question.split(' '):\n",
        "        if word in embeddings:\n",
        "            valid_words += 1\n",
        "            question_embedding += embeddings[word]\n",
        "    if valid_words > 0:\n",
        "        return question_embedding/valid_words\n",
        "    else:\n",
        "        return question_embedding"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYYVdFA_NYkT"
      },
      "source": [
        "Calculate the mean embedding vector for all the titles in our database and store it in all title embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "UoMqYufr2olA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50327ce3-b0ab-489a-b4e2-f07dbe2be9d0"
      },
      "source": [
        "all_title_embeddings = []\n",
        "for title in data.processed_title:\n",
        "    all_title_embeddings.append(question_to_vec(title, w2v_model))\n",
        "all_title_embeddings = np.array(all_title_embeddings)\n",
        "\n",
        "embeddings = pd.DataFrame(data = all_title_embeddings)\n",
        "embeddings.to_csv('/content/gdrive/My Drive/Stackoverflow_VS_extension/title_embeddings.csv', index=False)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "vwkLuBPv2olE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd818e8e-e7d9-4567-d877-31e1705acf98"
      },
      "source": [
        "all_title_embeddings = pd.read_csv('/content/gdrive/My Drive/Stackoverflow_VS_extension/title_embeddings.csv').values\n",
        "print(all_title_embeddings.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(147059, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AHrAH732olO"
      },
      "source": [
        "## Import Word Embedding Vectors for all words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqQrUq-h6Sq6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d839199-bbdf-4fed-aee8-4a97a4c59be4"
      },
      "source": [
        "## Embedding Matrix\n",
        "import pickle\n",
        "with open('/content/gdrive/My Drive/Stackoverflow_VS_extension/tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index)\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "W2V_SIZE = 300\n",
        "MAX_SEQUENCE_LENGTH = 300\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size+1, W2V_SIZE))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in w2v_model.wv:\n",
        "        embedding_matrix[i] = w2v_model.wv[word]\n",
        "print(embedding_matrix.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 471299 unique tokens.\n",
            "(471300, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRAylAHnOgy2"
      },
      "source": [
        "## Import and Load the tag predictor model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "HGo5x8s32olT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ba6dd3-5ec1-4788-a1db-64fbb8cae9bb"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding,GRU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from datetime import datetime\n",
        "from time import time\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size+1, W2V_SIZE, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
        "model.add(GRU(500, activation='relu',kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(150,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(500, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"adam\")\n",
        "\n",
        "model.load_weights('/content/gdrive/My Drive/Stackoverflow_VS_extension/Tag_predictor_weights.h5')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 300, 300)          141390000 \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 500)               1203000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 500)               2000      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 150)               75150     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 150)               600       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 500)               75500     \n",
            "=================================================================\n",
            "Total params: 142,746,250\n",
            "Trainable params: 1,354,950\n",
            "Non-trainable params: 141,391,300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "JscXAXlC2olY"
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "tag_encoder = MultiLabelBinarizer()\n",
        "\n",
        "# Returns the predicted tags in the form multiclass probablity\n",
        "def predict_tags_get_one_hot_vector(text):\n",
        "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=MAX_SEQUENCE_LENGTH)\n",
        "    prediction = model.predict([x_test])[0]\n",
        "    return prediction"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_0zalmKO-_7"
      },
      "source": [
        "## Query Normalization Functions\n",
        "These functions are used to preprocess the query that was given to our search. They tokenize the query, removes punctuation, remove stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "JpXufT572olh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "708e5854-6acb-4c03-91ca-2a79aa5a77a9"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "def tokenize_text(text):\n",
        "    \"Use spacy to tokenize.\"\n",
        "    tokens = EN.tokenizer(text)\n",
        "    return [token.text.lower() for token in tokens if not token.is_space]\n",
        "\n",
        "\n",
        "def to_lowercase(words):\n",
        "    \"\"\"convert to lowercase\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = word.lower()\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def remove_punctuation(words):\n",
        "    \"\"\"Remove punctuation \"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
        "        if new_word != '':\n",
        "            new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def remove_stopwords(words):\n",
        "    \"\"\"Remove stop words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word not in stopwords.words('english'):\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def normalize(words):\n",
        "    words = to_lowercase(words)\n",
        "    words = remove_punctuation(words)\n",
        "    words = remove_stopwords(words)\n",
        "    return words\n",
        "\n",
        "def tokenize_code(text):\n",
        "    \n",
        "    return RegexpTokenizer(r'\\w+').tokenize(text)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    return ' '.join(normalize(tokenize_text(text)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlfI6nXi2olq"
      },
      "source": [
        "## Indexing Search Results\n",
        "We use the Cosine Similarity as our main measure to index search result. Our searching process consist of:\n",
        "1. Preprocessing the query\n",
        "2. Predicting tags on our search query and caculating its cosine similarity with all question tags.\n",
        "3. Calculating query's mean embedding vector and calculating its cosine similarity with the mean embedding vectors of all questions in our database.\n",
        "\n",
        "We then add these two cosine similarity values with the score of each question to index our search results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8JZeBM_lxC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e0b8de-1621-4777-d83d-96e3318ec92e"
      },
      "source": [
        "\n",
        "data.tags = data.tags.apply(lambda x: x.split('|'))\n",
        "tag_freq_dict = {}\n",
        "for tags in data.tags:\n",
        "    for tag in tags:\n",
        "        if tag not in tag_freq_dict:\n",
        "            tag_freq_dict[tag] = 0\n",
        "        else:\n",
        "            tag_freq_dict[tag] += 1\n",
        "\n",
        "\n",
        "tags_to_use = 500\n",
        "tag_freq_dict_sorted = dict(sorted(tag_freq_dict.items(), key=lambda x: x[1], reverse=True))\n",
        "final_tags = list(tag_freq_dict_sorted.keys())[:tags_to_use]\n",
        "print(len(final_tags))\n",
        "\n",
        "\n",
        "final_tag_data = []\n",
        "for tags in data.tags:\n",
        "    temp = []\n",
        "    for tag in tags:\n",
        "        if tag in final_tags:\n",
        "            temp.append(tag)\n",
        "    final_tag_data.append(temp)\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "tag_encoder = MultiLabelBinarizer()\n",
        "tags_encoded = tag_encoder.fit_transform(final_tag_data)\n",
        "tags_encoded.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(147059, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "MTQmBtr92olr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "outputId": "644b1d18-c302-4309-c569-8502d460b291"
      },
      "source": [
        "from IPython.display import HTML\n",
        "import logging\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "search_string = \"Index out of bound\" \n",
        "original_string = search_string\n",
        "search_string = ' '.join(normalize(tokenize_text(search_string)))\n",
        "results_returned = \"5\" \n",
        "search_vect = np.array([question_to_vec(search_string, w2v_model)])    \n",
        "\n",
        "# Adding cosine similarity using title embeddings\n",
        "cosine_similarities = pd.Series(cosine_similarity(search_vect, all_title_embeddings)[0])\n",
        "predicted_tags = predict_tags_get_one_hot_vector(original_string)\n",
        "predicted_tags = np.array(predicted_tags)[np.newaxis]\n",
        "cosine_similarities_tags = pd.Series(cosine_similarity(predicted_tags, tags_encoded)[0])\n",
        "\n",
        "# Adding cosine similarity for predicted tags\n",
        "cosine_similarities+=cosine_similarities_tags\n",
        "\n",
        "# Taking overall score (votes) also into account\n",
        "cosine_similarities = cosine_similarities*(1 + 0.6*data.overall_scores )\n",
        "\n",
        "output =\"\"\n",
        "for i,j in cosine_similarities.nlargest(int(results_returned)).iteritems():\n",
        "    output += '<a target=\"_blank\" href='+ str(data.question_url[i])+'><h2>' + data.original_title[i] + '</h2></a>'\n",
        "    output +='<p style=\"font-family:verdana; font-size:110%;\"> '\n",
        "    output += data.question_content[i] + '</p><hr>'\n",
        "    \n",
        "output = '<h3>Results:</h3>'+output\n",
        "display(HTML(output))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Results:</h3><a target=\"_blank\" href=https://stackoverflow.com/questions/52222812><h2>List index out of bound</h2></a><p style=\"font-family:verdana; font-size:110%;\"> list index bound single unique element list n similar numbers list</p><hr><a target=\"_blank\" href=https://stackoverflow.com/questions/176918><h2>Finding the index of an item in a list</h2></a><p style=\"font-family:verdana; font-size:110%;\"> finding index item list given list item list bar get index 1 python</p><hr><a target=\"_blank\" href=https://stackoverflow.com/questions/63598685><h2>IndexError: index out of bound (Pandas)</h2></a><p style=\"font-family:verdana; font-size:110%;\"> indexerror index bound pandas getting error pandas please help</p><hr><a target=\"_blank\" href=https://stackoverflow.com/questions/46029071><h2>Error with index. index 0 is out of bounds for axis 0 with size 0</h2></a><p style=\"font-family:verdana; font-size:110%;\"> error index index 0 bounds axis 0 size 0 run code get error</p><hr><a target=\"_blank\" href=https://stackoverflow.com/questions/47469786><h2>Index of numpy.ndarray</h2></a><p style=\"font-family:verdana; font-size:110%;\"> index numpyndarray split numpyndarray object</p><hr>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtmtVMZs6u-c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}